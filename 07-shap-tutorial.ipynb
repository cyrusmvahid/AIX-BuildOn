{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95496219",
   "metadata": {},
   "source": [
    "# A Gentle Introduction to AI Explainability - part 5: SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6dd323",
   "metadata": {},
   "source": [
    "## Implementation Example\n",
    "in the [theoretical post](06-shape.md) about SHAP, we explored the SHAP paper. We now take a look at a tutorial of SHAP. Here we focus on a practical tutorial in which we use VGG16 to predict objects in an image before attempting to explain it using Kernel SHAP. THe full code can be found [here](08-shap-example.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037c00eb",
   "metadata": {},
   "source": [
    "#### Loading an Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616d9969",
   "metadata": {},
   "source": [
    "```python\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "pil_img = Image.open(\"data/boyz2.jpeg\")\n",
    "pil_img.convert(\"RGB\")\n",
    "\n",
    "resize_transform  = transforms.Resize((224,224))\n",
    "tensor_transform = transforms.ToTensor()\n",
    "\n",
    "\n",
    "pil_img = resize_transform(pil_img)\n",
    "plt.imshow(pil_img)\n",
    "pil_img = tensor_transform(pil_img)#.numpy()\n",
    "#normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                                std=[0.229, 0.224, 0.225])  \n",
    "#pil_img = normalize(pil_img)\n",
    "pil_img = np.transpose(pil_img, (1,2,0))\n",
    "pil_img = pil_img * 255\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8d27c6",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <img img align=\"center\"  width=\"224\" height=\"224\" src='images/boyzplt.png''>\n",
    "    <figcaption>\n",
    "    </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8709a63",
   "metadata": {},
   "source": [
    "#### Segmenting the image to 50 segments so we do not end up explaining every pixel.\n",
    "```python\n",
    "from skimage.segmentation import slic\n",
    "\n",
    "segments_slic_pil = slic(pil_img, n_segments=50, compactness=30, sigma=3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16111485",
   "metadata": {},
   "source": [
    "#### define a function that depends on a binary mask representing if an image region is hidden\n",
    "\n",
    "```python\n",
    "def mask_image(zs, segmentation, image, background=None):\n",
    "    if background is None:\n",
    "        background = image.mean((0,1))\n",
    "    out = np.zeros((zs.shape[0], image.shape[0], image.shape[1], image.shape[2]))\n",
    "    for i in range(zs.shape[0]):\n",
    "        out[i,:,:,:] = image\n",
    "        for j in range(zs.shape[1]):\n",
    "            if zs[i,j] == 0:\n",
    "                out[i][segmentation == j,:] = background\n",
    "    return out\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e708ab31",
   "metadata": {},
   "source": [
    "#### Creating a predictor that works on super-pixels as opposed to the original image.\n",
    "\n",
    "```python\n",
    "from keras.applications.vgg16 import VGG16\n",
    "model = VGG15()\n",
    "def f(z):\n",
    "    print(\"inside f\")\n",
    "    return model.predict(preprocess_input(mask_image(z, segments_slic, pil_img, 255)))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9939be",
   "metadata": {},
   "source": [
    "#### Creating an explainer using shap library\n",
    "```python\n",
    "import shap\n",
    "explainer = shap.KernelExplainer(f, np.zeros((1,50)))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736c0d88",
   "metadata": {},
   "source": [
    "#### Computing Shaply values using our explainer. \n",
    "We run VGG 100 times on the perturbed dataset.\n",
    "```python\n",
    "shap_values = explainer.shap_values(np.ones((1,50)), nsamples=1000) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2147882d",
   "metadata": {},
   "source": [
    "#### Visualization of the explanation\n",
    "In explaining how the white dog has been identified as a west highland terrier, we can see the face (colour green) and the positive contribution of 0.1 has the highest impact. Notably we can also observe that the red zones have the most negative imact.\n",
    "\n",
    "<figure>\n",
    "    <img img align=\"center\"  \" src='images/boyzexplained.png'>\n",
    "    <figcaption>\n",
    "    </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafe69f3",
   "metadata": {},
   "source": [
    "\n",
    "# References\n",
    "1. https://arxiv.org/pdf/1602.04938v1.pdf\n",
    "2. https://arxiv.org/pdf/2011.07876.pdf\n",
    "3. https://www.oreilly.com/content/introduction-to-local-interpretable-model-agnostic-explanations-lime/\n",
    "4. https://github.com/marcotcr/lime/tree/master/doc/notebooks\n",
    "5. https://arxiv.org/pdf/1705.07874.pdf\n",
    "6. https://vknight.org/Year_3_game_theory_course/Content/Chapter_16_Cooperative_games/\n",
    "7. https://www.rand.org/content/dam/rand/pubs/papers/2021/P295.pdf\n",
    "8. https://www.wifa.uni-leipzig.de/fileadmin/Fakultät_Wifa/Institut_für_Theoretische_Volkswirtschaftslehre/Professur_Mikroökonomik/Cooperative_game_theory/B1_gl.pdf\n",
    "9. https://www.youtube.com/watch?v=9OFMRiAVH-w\n",
    "10 https://arxiv.org/pdf/1705.07874.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16ce2a8-c282-4e94-8cc0-c4d0e4346264",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
